{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from einops import rearrange\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[5, 7, 3,  ..., 8, 2, 5],\n",
       "         [2, 4, 2,  ..., 2, 2, 5],\n",
       "         [7, 5, 2,  ..., 2, 2, 3],\n",
       "         ...,\n",
       "         [4, 3, 6,  ..., 3, 7, 8],\n",
       "         [9, 6, 9,  ..., 7, 7, 4],\n",
       "         [8, 2, 5,  ..., 4, 8, 3]],\n",
       "\n",
       "        [[6, 6, 8,  ..., 2, 2, 9],\n",
       "         [5, 2, 9,  ..., 6, 5, 6],\n",
       "         [9, 9, 5,  ..., 3, 5, 7],\n",
       "         ...,\n",
       "         [7, 7, 5,  ..., 3, 7, 7],\n",
       "         [2, 9, 7,  ..., 6, 9, 9],\n",
       "         [4, 8, 6,  ..., 4, 4, 7]],\n",
       "\n",
       "        [[7, 5, 6,  ..., 3, 8, 3],\n",
       "         [6, 2, 6,  ..., 4, 3, 3],\n",
       "         [9, 5, 7,  ..., 6, 8, 6],\n",
       "         ...,\n",
       "         [6, 8, 5,  ..., 7, 3, 8],\n",
       "         [7, 8, 6,  ..., 5, 4, 2],\n",
       "         [7, 6, 3,  ..., 6, 3, 5]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randint(2,10,(3,256,256))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[5, 7, 3,  ..., 8, 2, 5],\n",
       "          [2, 4, 2,  ..., 2, 2, 5],\n",
       "          [7, 5, 2,  ..., 2, 2, 3],\n",
       "          ...,\n",
       "          [6, 2, 8,  ..., 8, 3, 3],\n",
       "          [9, 4, 3,  ..., 7, 9, 2],\n",
       "          [4, 7, 6,  ..., 2, 4, 5]],\n",
       "\n",
       "         [[5, 8, 7,  ..., 9, 4, 8],\n",
       "          [6, 7, 7,  ..., 4, 9, 3],\n",
       "          [6, 8, 3,  ..., 3, 4, 7],\n",
       "          ...,\n",
       "          [6, 3, 9,  ..., 6, 7, 9],\n",
       "          [2, 5, 8,  ..., 3, 8, 9],\n",
       "          [4, 7, 4,  ..., 2, 7, 7]],\n",
       "\n",
       "         [[2, 9, 8,  ..., 3, 5, 9],\n",
       "          [2, 4, 3,  ..., 2, 9, 2],\n",
       "          [4, 6, 7,  ..., 8, 8, 9],\n",
       "          ...,\n",
       "          [3, 5, 8,  ..., 7, 8, 8],\n",
       "          [5, 9, 8,  ..., 4, 2, 6],\n",
       "          [6, 7, 4,  ..., 3, 7, 8]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[8, 4, 4,  ..., 8, 9, 4],\n",
       "          [2, 8, 3,  ..., 5, 6, 4],\n",
       "          [6, 6, 8,  ..., 2, 7, 4],\n",
       "          ...,\n",
       "          [3, 3, 4,  ..., 2, 2, 8],\n",
       "          [9, 2, 8,  ..., 8, 5, 5],\n",
       "          [9, 4, 7,  ..., 8, 2, 9]],\n",
       "\n",
       "         [[4, 2, 8,  ..., 7, 9, 5],\n",
       "          [2, 2, 7,  ..., 3, 5, 6],\n",
       "          [2, 2, 8,  ..., 9, 2, 9],\n",
       "          ...,\n",
       "          [7, 2, 3,  ..., 2, 9, 7],\n",
       "          [8, 3, 8,  ..., 9, 9, 3],\n",
       "          [2, 9, 3,  ..., 3, 5, 8]],\n",
       "\n",
       "         [[9, 9, 6,  ..., 4, 5, 5],\n",
       "          [2, 8, 6,  ..., 2, 8, 2],\n",
       "          [2, 5, 8,  ..., 4, 8, 5],\n",
       "          ...,\n",
       "          [4, 3, 6,  ..., 3, 7, 8],\n",
       "          [9, 6, 9,  ..., 7, 7, 4],\n",
       "          [8, 2, 5,  ..., 4, 8, 3]]],\n",
       "\n",
       "\n",
       "        [[[6, 6, 8,  ..., 2, 2, 9],\n",
       "          [5, 2, 9,  ..., 6, 5, 6],\n",
       "          [9, 9, 5,  ..., 3, 5, 7],\n",
       "          ...,\n",
       "          [2, 3, 4,  ..., 9, 3, 8],\n",
       "          [8, 7, 4,  ..., 9, 3, 9],\n",
       "          [3, 4, 9,  ..., 9, 8, 9]],\n",
       "\n",
       "         [[4, 7, 5,  ..., 2, 8, 7],\n",
       "          [2, 2, 6,  ..., 6, 8, 5],\n",
       "          [5, 2, 6,  ..., 5, 9, 4],\n",
       "          ...,\n",
       "          [9, 2, 9,  ..., 3, 4, 2],\n",
       "          [7, 7, 4,  ..., 3, 7, 2],\n",
       "          [8, 4, 8,  ..., 6, 9, 4]],\n",
       "\n",
       "         [[8, 9, 2,  ..., 7, 7, 2],\n",
       "          [2, 7, 5,  ..., 9, 6, 6],\n",
       "          [4, 9, 4,  ..., 5, 5, 8],\n",
       "          ...,\n",
       "          [2, 9, 9,  ..., 8, 2, 6],\n",
       "          [3, 4, 3,  ..., 4, 4, 7],\n",
       "          [2, 7, 8,  ..., 2, 6, 6]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[4, 9, 7,  ..., 4, 8, 5],\n",
       "          [7, 2, 6,  ..., 9, 5, 6],\n",
       "          [3, 7, 3,  ..., 7, 5, 4],\n",
       "          ...,\n",
       "          [9, 7, 7,  ..., 5, 3, 8],\n",
       "          [9, 2, 7,  ..., 9, 3, 5],\n",
       "          [5, 2, 2,  ..., 4, 5, 9]],\n",
       "\n",
       "         [[9, 4, 5,  ..., 5, 3, 2],\n",
       "          [4, 5, 9,  ..., 9, 5, 3],\n",
       "          [2, 9, 6,  ..., 8, 4, 9],\n",
       "          ...,\n",
       "          [5, 5, 8,  ..., 3, 5, 6],\n",
       "          [5, 2, 2,  ..., 7, 2, 5],\n",
       "          [7, 6, 6,  ..., 9, 3, 4]],\n",
       "\n",
       "         [[8, 2, 5,  ..., 2, 4, 8],\n",
       "          [3, 3, 3,  ..., 2, 5, 7],\n",
       "          [4, 8, 7,  ..., 5, 8, 5],\n",
       "          ...,\n",
       "          [7, 7, 5,  ..., 3, 7, 7],\n",
       "          [2, 9, 7,  ..., 6, 9, 9],\n",
       "          [4, 8, 6,  ..., 4, 4, 7]]],\n",
       "\n",
       "\n",
       "        [[[7, 5, 6,  ..., 3, 8, 3],\n",
       "          [6, 2, 6,  ..., 4, 3, 3],\n",
       "          [9, 5, 7,  ..., 6, 8, 6],\n",
       "          ...,\n",
       "          [6, 4, 5,  ..., 8, 6, 3],\n",
       "          [6, 4, 3,  ..., 4, 5, 5],\n",
       "          [8, 8, 8,  ..., 3, 4, 4]],\n",
       "\n",
       "         [[2, 7, 8,  ..., 4, 4, 8],\n",
       "          [6, 5, 7,  ..., 5, 7, 2],\n",
       "          [8, 7, 8,  ..., 3, 9, 8],\n",
       "          ...,\n",
       "          [3, 5, 8,  ..., 8, 2, 8],\n",
       "          [3, 6, 7,  ..., 7, 6, 7],\n",
       "          [8, 5, 4,  ..., 3, 5, 5]],\n",
       "\n",
       "         [[6, 6, 2,  ..., 3, 6, 7],\n",
       "          [6, 7, 7,  ..., 3, 6, 8],\n",
       "          [3, 2, 6,  ..., 9, 4, 3],\n",
       "          ...,\n",
       "          [8, 2, 4,  ..., 5, 8, 5],\n",
       "          [8, 9, 2,  ..., 9, 7, 3],\n",
       "          [7, 2, 3,  ..., 9, 5, 6]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[7, 8, 7,  ..., 6, 5, 5],\n",
       "          [6, 5, 2,  ..., 5, 2, 8],\n",
       "          [3, 3, 7,  ..., 2, 4, 5],\n",
       "          ...,\n",
       "          [8, 4, 9,  ..., 9, 9, 5],\n",
       "          [3, 3, 8,  ..., 6, 7, 7],\n",
       "          [7, 6, 4,  ..., 2, 6, 6]],\n",
       "\n",
       "         [[5, 8, 4,  ..., 6, 8, 2],\n",
       "          [8, 6, 5,  ..., 5, 5, 9],\n",
       "          [7, 3, 3,  ..., 4, 8, 5],\n",
       "          ...,\n",
       "          [7, 2, 8,  ..., 3, 3, 5],\n",
       "          [5, 4, 5,  ..., 7, 3, 6],\n",
       "          [7, 7, 9,  ..., 7, 7, 3]],\n",
       "\n",
       "         [[6, 3, 7,  ..., 6, 6, 3],\n",
       "          [3, 2, 5,  ..., 8, 7, 9],\n",
       "          [3, 6, 8,  ..., 8, 4, 2],\n",
       "          ...,\n",
       "          [6, 8, 5,  ..., 7, 3, 8],\n",
       "          [7, 8, 6,  ..., 5, 4, 2],\n",
       "          [7, 6, 3,  ..., 6, 3, 5]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(3,16,16,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops in /raid/nlp/pranavg/anaconda3/envs/llama2/lib/python3.11/site-packages (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 64\n",
    "T = 30\n",
    "P = 256\n",
    "D = 768\n",
    "\n",
    "sim = torch.rand(B,T,P).to('cuda')\n",
    "l = torch.rand(B,T,D).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(B,T,D).to('cuda')\n",
    "b = torch.rand(B,T,D).to('cuda')\n",
    "mask = torch.eye(B,T).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_pairwise_contrastive_loss(a, b, mask):\n",
    "    batch_size, seq_len, _ = a.shape\n",
    "    mask_logits = ~mask.bool().unsqueeze(-1).repeat(1,1,seq_len)\n",
    "    print(mask_logits.shape)\n",
    "    labels = torch.eye(seq_len).repeat(batch_size,1,1).to(a.device)\n",
    "    logits = torch.einsum('bmd,bnd->bmn',a,b)\n",
    "    INF = torch.finfo(logits.dtype).min\n",
    "    logits = logits.masked_fill(mask_logits, INF)\n",
    "    \n",
    "    # flatten all vectors\n",
    "    logits = torch.flatten(logits, 0, 1)\n",
    "    labels = torch.flatten(labels, 0, 1)\n",
    "    mask_logits = torch.flatten(mask_logits, 0, 1)\n",
    "    print(mask_logits)\n",
    "    \n",
    "    # loss\n",
    "    log_prob = F.log_softmax(logits, dim=-1)\n",
    "    loss = -log_prob*labels\n",
    "    print(loss)\n",
    "    loss = loss[mask_logits].mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 30, 30])\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True],\n",
      "        ...,\n",
      "        [ True,  True,  True,  ...,  True,  True,  True],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True]], device='cuda:0')\n",
      "tensor([[3.9743, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 3.4012, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 3.4012,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 3.4012, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 3.4012, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 3.4012]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.1134, device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_pairwise_contrastive_loss(a,b,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 30, 256])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = sim/(torch.max(sim, dim=-1).values.unsqueeze(-1) - torch.min(sim, dim=-1).values.unsqueeze(-1))\n",
    "sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[5.7560e-03, 2.7589e-03, 4.8367e-04,  ..., 2.7247e-03,\n",
       "          5.6856e-03, 7.2506e-03],\n",
       "         [7.4191e-04, 1.0250e-05, 3.9257e-03,  ..., 1.5827e-03,\n",
       "          2.9699e-03, 6.9620e-03],\n",
       "         [5.4153e-03, 4.9174e-03, 4.3338e-03,  ..., 1.7716e-03,\n",
       "          5.0803e-03, 4.6817e-03],\n",
       "         ...,\n",
       "         [4.8410e-03, 6.4017e-03, 6.9732e-03,  ..., 6.1932e-03,\n",
       "          5.9526e-03, 3.9711e-03],\n",
       "         [7.5591e-03, 1.7085e-03, 5.4239e-03,  ..., 4.9801e-03,\n",
       "          4.5435e-03, 6.6362e-03],\n",
       "         [2.7200e-03, 6.9640e-03, 1.8543e-03,  ..., 1.8166e-03,\n",
       "          1.9588e-04, 3.8905e-04]],\n",
       "\n",
       "        [[1.3036e-03, 1.2784e-03, 7.7186e-03,  ..., 2.7483e-03,\n",
       "          1.9372e-03, 7.9499e-03],\n",
       "         [5.8103e-03, 6.6702e-03, 4.1411e-03,  ..., 4.6495e-03,\n",
       "          5.6949e-03, 4.9467e-03],\n",
       "         [5.7349e-03, 1.8169e-03, 4.7077e-04,  ..., 1.5114e-03,\n",
       "          9.0372e-04, 3.8160e-03],\n",
       "         ...,\n",
       "         [5.8712e-03, 2.6464e-03, 6.2165e-03,  ..., 1.7041e-03,\n",
       "          6.0497e-03, 6.4417e-03],\n",
       "         [4.0254e-03, 2.0820e-03, 5.9589e-03,  ..., 5.1358e-03,\n",
       "          5.2163e-04, 7.0654e-03],\n",
       "         [5.6432e-03, 4.4063e-03, 2.4816e-03,  ..., 5.0354e-03,\n",
       "          1.6475e-03, 2.6894e-03]],\n",
       "\n",
       "        [[6.9230e-03, 5.9943e-03, 1.5875e-03,  ..., 6.7491e-03,\n",
       "          2.8327e-03, 3.7450e-03],\n",
       "         [3.8895e-03, 3.5619e-03, 5.2557e-03,  ..., 2.4047e-03,\n",
       "          7.3390e-03, 1.6599e-03],\n",
       "         [3.9848e-03, 5.0898e-04, 1.9055e-03,  ..., 1.7435e-03,\n",
       "          1.1033e-03, 3.4302e-03],\n",
       "         ...,\n",
       "         [3.4382e-03, 6.3078e-03, 5.6951e-03,  ..., 4.1027e-03,\n",
       "          6.2981e-03, 7.0189e-03],\n",
       "         [1.5216e-03, 1.1010e-03, 3.6778e-03,  ..., 3.7438e-04,\n",
       "          7.2611e-03, 4.0690e-03],\n",
       "         [6.5217e-03, 3.4404e-06, 7.9071e-04,  ..., 1.7200e-03,\n",
       "          5.9103e-03, 2.2478e-03]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[3.1454e-04, 5.2591e-04, 6.0741e-03,  ..., 4.4813e-03,\n",
       "          1.1306e-03, 3.6355e-03],\n",
       "         [6.5964e-04, 1.7615e-03, 7.1039e-03,  ..., 3.8414e-03,\n",
       "          2.8357e-03, 1.9348e-03],\n",
       "         [6.0337e-04, 4.7859e-03, 2.6455e-03,  ..., 3.1961e-03,\n",
       "          7.3185e-05, 9.1791e-04],\n",
       "         ...,\n",
       "         [3.6416e-03, 3.1892e-03, 3.0599e-03,  ..., 4.2272e-04,\n",
       "          2.3535e-03, 6.2189e-03],\n",
       "         [4.9476e-03, 7.6365e-03, 3.7624e-03,  ..., 2.6589e-04,\n",
       "          5.9705e-03, 3.7223e-03],\n",
       "         [5.8837e-03, 7.6134e-03, 3.4542e-04,  ..., 7.6155e-03,\n",
       "          6.3970e-03, 6.3286e-03]],\n",
       "\n",
       "        [[5.9500e-03, 5.3021e-03, 6.7010e-03,  ..., 2.1610e-03,\n",
       "          7.3361e-03, 3.2067e-03],\n",
       "         [4.9838e-03, 1.0173e-03, 1.0944e-04,  ..., 7.4110e-03,\n",
       "          1.6233e-03, 4.0032e-03],\n",
       "         [3.4738e-04, 1.9079e-03, 3.3282e-03,  ..., 4.4933e-03,\n",
       "          3.2927e-03, 2.3563e-03],\n",
       "         ...,\n",
       "         [5.0629e-04, 2.9817e-03, 7.3592e-03,  ..., 5.6252e-03,\n",
       "          7.8220e-04, 6.0718e-03],\n",
       "         [2.9048e-03, 1.4318e-03, 6.2065e-03,  ..., 4.3397e-03,\n",
       "          1.0819e-03, 7.7537e-03],\n",
       "         [7.4235e-03, 4.6683e-03, 2.3003e-03,  ..., 3.9703e-03,\n",
       "          5.3268e-03, 5.6517e-03]],\n",
       "\n",
       "        [[7.2678e-03, 1.6838e-04, 5.2367e-03,  ..., 5.0295e-03,\n",
       "          7.6823e-03, 1.9793e-03],\n",
       "         [6.2079e-03, 6.6478e-03, 4.9182e-03,  ..., 4.2803e-03,\n",
       "          2.7998e-03, 1.0321e-03],\n",
       "         [5.0385e-03, 1.6960e-03, 6.7105e-03,  ..., 6.2638e-03,\n",
       "          2.3705e-03, 5.9123e-03],\n",
       "         ...,\n",
       "         [7.1331e-03, 4.2803e-03, 6.8492e-03,  ..., 7.6783e-03,\n",
       "          7.4473e-03, 1.6019e-03],\n",
       "         [1.5385e-03, 6.5096e-03, 3.8508e-03,  ..., 3.5192e-03,\n",
       "          6.3923e-03, 1.9949e-04],\n",
       "         [5.8421e-03, 7.2809e-03, 3.2831e-03,  ..., 4.7607e-03,\n",
       "          4.8678e-03, 3.8293e-03]]], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim/torch.sum(sim, dim=-1).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_token_embed = torch.rand(64, 34, 768).to('cuda')\n",
    "v_patch_embed = torch.rand(64, 256, 768).to('cuda')\n",
    "language_mask = torch.rand(64,34).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 34, 256])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity = torch.einsum('btd,bpd->btp',l_token_embed, v_patch_embed)\n",
    "similarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = (similarity-torch.min(similarity, dim=-1).values.unsqueeze(-1))/(torch.max(similarity, dim=-1).values - torch.min(similarity, dim=-1).values).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = torch.where(similarity < 0.5, 0.0, similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 34, 768])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_align_weights = similarity/torch.sum(similarity, dim=-1).unsqueeze(-1)\n",
    "l_grouped_v_patch_embed = torch.einsum('btp,bpd->btd', v_align_weights, v_patch_embed)\n",
    "l_grouped_v_patch_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_logits = (1.0-language_mask).unsqueeze(1).expand(-1, l_token_embed.shape[1], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_token_targets = torch.eye(l_token_embed.shape[1]).unsqueeze(0).expand(l_token_embed.shape[0], -1, -1).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_token_i2t = torch.einsum('bmd,bnd->bmn', l_grouped_v_patch_embed, l_token_embed)\n",
    "sim_token_t2i = torch.einsum('bmd,bnd->bmn', l_token_embed, l_grouped_v_patch_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_token_i2t = torch.flatten(sim_token_i2t, start_dim=0, end_dim=1)\n",
    "sim_token_t2i = torch.flatten(sim_token_t2i, start_dim=0, end_dim=1)\n",
    "sim_token_targets = torch.flatten(sim_token_targets, start_dim=0, end_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[193.3438, 187.4263, 193.9430,  ..., 200.3852, 193.4124, 196.0533],\n",
       "        [192.4890, 188.4600, 194.1176,  ..., 200.2485, 193.5657, 196.0668],\n",
       "        [192.7252, 187.8056, 195.6976,  ..., 200.6323, 193.8745, 196.2714],\n",
       "        ...,\n",
       "        [203.8492, 191.7299, 197.6203,  ..., 199.5779, 201.3323, 200.3034],\n",
       "        [203.6092, 191.7253, 197.4860,  ..., 198.6888, 201.8735, 200.2687],\n",
       "        [203.4427, 191.5200, 197.1854,  ..., 198.2348, 200.8883, 200.6276]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_token_i2t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_logits = torch.flatten(mask_logits, start_dim=0, end_dim=1)\n",
    "loss_token_i2t = -torch.nn.functional.log_softmax(sim_token_i2t - mask_logits * float('inf'), dim=-1)*sim_token_targets\n",
    "loss_token_t2i = -torch.nn.functional.log_softmax(sim_token_t2i - mask_logits * float('inf'), dim=-1)*sim_token_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2176, 34])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_token_i2t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2176, 34])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1-mask_logits).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Assuming logits, mask_logits, and labels are your input tensors\n",
    "\n",
    "# Set elements of mask_logits to negative infinity where mask is True\n",
    "mask = (mask_logits == 1)\n",
    "sim_token_i2t[mask] = float('-inf')\n",
    "\n",
    "# Compute softmax cross-entropy loss\n",
    "loss = F.cross_entropy(sim_token_i2t, sim_token_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.3092, device='cuda:0')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (34) must match the size of tensor b (73984) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mlog_softmax(\u001b[43msim_token_i2t\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmask_logits\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39msim_token_targets\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (34) must match the size of tensor b (73984) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "torch.nn.functional.log_softmax(sim_token_i2t - mask_logits * float('inf'), dim=-1)*sim_token_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -1.6944, -16.1906,  -7.4569,  ...,  -8.1323, -11.3844,  -8.9391],\n",
      "        [ -2.2487, -15.0631,  -7.3145,  ...,  -8.1771, -11.2736,  -8.5244],\n",
      "        [ -2.3877, -16.1607,  -6.1608,  ...,  -8.1342, -11.1276,  -8.7727],\n",
      "        ...,\n",
      "        [ -6.2352, -10.0961,  -3.1049,  ...,  -1.0768,  -7.6882,  -6.7549],\n",
      "        [ -5.8312,  -9.6440,  -2.7862,  ...,  -1.9446,  -6.5280,  -7.0041],\n",
      "        [ -6.1809,  -9.8137,  -2.5071,  ...,  -2.0764,  -7.6193,  -5.6642]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.nn.functional.log_softmax(sim_token_i2t + (mask_logits + 1e-45).log(), dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 34, 34])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = (similarity-torch.min(similarity, dim=-1).values)/(torch.max(similarity, dim=-1).values - torch.min(similarity, dim=-1).values)\n",
    "similarity = torch.where(similarity < self.similarity_threshold, 0.0, similarity)\n",
    "v_align_weights = similarity/sum(similarity, dim=-1)\n",
    "l_grouped_v_patch_embed = torch.einsum('btp,bpd->btd', v_align_weights, v_patch_embed)\n",
    "l_grouped_v_patch_embed = F.normalize(l_grouped_v_patch_embed, dim=-1)\n",
    "l_token_embed = F.normalize(l_token_embed, dim=-1)\n",
    "mask_logits = (1.0-language_mask).unsqeeze(1).expand(-1, l_token_embed.shape[1], -1)\n",
    "sim_token_targets = torch.eye(l_token_embed.shape[1]).unsqeeze(0).expand(l_token_embed.shape[0], -1, -1)\n",
    "sim_token_i2t = torch.einsum('bmd,bnd->bmn', l_grouped_v_patch_embed, l_token_embed) / self.temp_token\n",
    "sim_token_t2i = torch.einsum('bmd,bnd->bmn', l_token_embed, l_grouped_v_patch_embed) / self.temp_token\n",
    "sim_token_i2t = torch.flatten(sim_token_i2t, start_dim=0, end_dim=1)\n",
    "sim_token_t2i = torch.flatten(sim_token_t2i, start_dim=0, end_dim=1)\n",
    "sim_token_targets = torch.flatten(sim_token_targets, start_dim=0, end_dim=1)\n",
    "mask_logits = torch.flatten(mask_logits, start_dim=0, end_dim=1)\n",
    "loss_token_i2t = torch.sum(-torch.sum(F.log_softmax(sim_token_i2t - mask_logits * float('inf'), dim=-1)*sim_token_targets, dim=-1))/torch.sum(language_mask)\n",
    "loss_token_t2i = torch.sum(-torch.sum(F.log_softmax(sim_token_t2i - mask_logits * float('inf'), dim=-1)*sim_token_targets, dim=-1))/torch.sum(language_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.tensor([2,3,4,5,7])\n",
    "idx_all = torch.tensor([1,2,3,4,5,6,7,8,9,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = idx.view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_idx = torch.eq(idx, idx_all).float()\n",
    "pos_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_idx.sum(1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-200],\n",
       "        [-200],\n",
       "        [-200],\n",
       "        [-200],\n",
       "        [-200],\n",
       "        [-200],\n",
       "        [-200],\n",
       "        [-200],\n",
       "        [-200],\n",
       "        [-200]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full((10,1),-200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_neg = torch.full((len(idx),1),-200)\n",
    "idx_neg_queue = torch.full((len(idx),1),-300)\n",
    "idx_neg_queue = torch.cat([idx, idx_neg_queue], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-200],\n",
       "        [-200],\n",
       "        [-200],\n",
       "        [-200],\n",
       "        [-200]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2],\n",
       "        [   3],\n",
       "        [   4],\n",
       "        [   5],\n",
       "        [   7],\n",
       "        [-300],\n",
       "        [-300],\n",
       "        [-300],\n",
       "        [-300],\n",
       "        [-300]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_neg_queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_targets = pos_idx / pos_idx.sum(1,keepdim=True)\n",
    "sim_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 3])\n",
      "tensor([[[1, 1, 1]],\n",
      "\n",
      "        [[0, 0, 0]]])\n",
      "torch.Size([2, 3])\n",
      "tensor([[0, 0, 0],\n",
      "        [1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[[1,1,1]],[[0,0,0]]])\n",
    "b = torch.tensor([[0,0,0],[1,1,1]])\n",
    "print(a.shape)\n",
    "print(a)\n",
    "print(b.shape)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 1, 1],\n",
      "         [2, 2, 2]],\n",
      "\n",
      "        [[0, 0, 0],\n",
      "         [1, 1, 1]]])\n",
      "torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "c = a+b\n",
    "print(c)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "d = torch.tensor([[[1, 0, 0],[0, 1, 0]],\n",
    "     [[0, 0, 1],[0, 0, 0]]])\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = torch.matmul(c.unsqueeze(1),d.permute(0,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.shape #[txt, img, txt+img_dom, img+txt_dom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0],\n",
       "         [0, 1, 0]],\n",
       "\n",
       "        [[0, 0, 1],\n",
       "         [0, 0, 0]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 2, 2])\n",
      "torch.Size([2, 2, 2])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(e.shape)\n",
    "f,_ = e.max(dim=-1)\n",
    "print(f.shape)\n",
    "g,_ = f.max(dim=-1)\n",
    "print(g.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2],\n",
       "        [1, 1]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "f = c.unsqueeze(1)\n",
    "print(f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(64,256)\n",
    "y = torch.rand(19,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [64, 256] at entry 0 and [19, 256] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [64, 256] at entry 0 and [19, 256] at entry 1"
     ]
    }
   ],
   "source": [
    "z = torch.stack([x,y], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.rand(5000,5000)\n",
    "topk_sim1, topk_idx1 = z.topk(k=10, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2762, 4839, 4376,  ..., 1090, 4061, 2072],\n",
       "        [4009, 3231, 4537,  ..., 3896, 4231, 2385],\n",
       "        [4648,  661, 1059,  ..., 4951, 3614, 4642],\n",
       "        ...,\n",
       "        [3244, 3532, 4910,  ..., 4751, 2654, 2580],\n",
       "        [3426, 3192, 1365,  ...,  333, 2224, 2002],\n",
       "        [  85, 1648, 2967,  ..., 4040, 1475, 4555]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5000])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 10])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_idx1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = torch.rand(5000,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 10, 256])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[topk_idx1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = s[topk_idx1[1]]\n",
    "b = s[topk_idx1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "a = torch.rand(5000,256)\n",
    "a_dom = torch.rand(5000,256)\n",
    "b = torch.rand(5000,256)\n",
    "b_dom = torch.rand(5000,256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 269/5000 [00:49<14:28,  5.45it/s]\n",
      "  0%|          | 0/5000 [00:49<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m txn \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tx_d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(a_dom)):\n\u001b[0;32m---> 10\u001b[0m     txn\u001b[38;5;241m.\u001b[39mappend(\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma_dom\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtx_d\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     11\u001b[0m txn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(txn, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     12\u001b[0m sim \u001b[38;5;241m=\u001b[39m imn \u001b[38;5;241m@\u001b[39m txn\u001b[38;5;241m.\u001b[39mt()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py:4719\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(input, p, dim, eps, out)\u001b[0m\n\u001b[1;32m   4717\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(normalize, (\u001b[38;5;28minput\u001b[39m, out), \u001b[38;5;28minput\u001b[39m, p\u001b[38;5;241m=\u001b[39mp, dim\u001b[38;5;241m=\u001b[39mdim, eps\u001b[38;5;241m=\u001b[39meps, out\u001b[38;5;241m=\u001b[39mout)\n\u001b[1;32m   4718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4719\u001b[0m     denom \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mclamp_min(eps)\u001b[38;5;241m.\u001b[39mexpand_as(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m   4720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m/\u001b[39m denom\n\u001b[1;32m   4721\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py:708\u001b[0m, in \u001b[0;36mTensor.norm\u001b[0;34m(self, p, dim, keepdim, dtype)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    706\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mnorm, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, p\u001b[38;5;241m=\u001b[39mp, dim\u001b[38;5;241m=\u001b[39mdim, keepdim\u001b[38;5;241m=\u001b[39mkeepdim, dtype\u001b[38;5;241m=\u001b[39mdtype\n\u001b[1;32m    707\u001b[0m     )\n\u001b[0;32m--> 708\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/functional.py:1611\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m   1609\u001b[0m _p \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m p\n\u001b[1;32m   1610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvector_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1612\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1613\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mvector_norm(\u001b[38;5;28minput\u001b[39m, _p, _dim, keepdim, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sims = torch.rand(len(a),len(b))\n",
    "for im in tqdm(range(len(a))):\n",
    "    imn = []\n",
    "    for im_d in range(len(b_dom)):\n",
    "        imn.append(F.normalize(a[im] + b_dom[im_d],dim=-1))\n",
    "    imn = torch.stack(imn, dim=0)\n",
    "    for tx in tqdm(range(len(b))):\n",
    "        txn = []\n",
    "        for tx_d in range(len(a_dom)):\n",
    "            txn.append(F.normalize(b[tx] + a_dom[tx_d], dim=-1))\n",
    "        txn = torch.stack(txn, dim=0)\n",
    "        sim = imn @ txn.t()\n",
    "        sims[im,tx] = torch.max(torch.max(sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoint_best_5.pth'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'checkpoint_best_{}.pth'.format(str(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
