{alpha: 0.4, ann_root: annotation, batch_size_test: 64, batch_size_train: 64, coco_gt_root: annotation/coco_gt,
dataset: WIDO, image_root: /workspace/multimodal/data/multimodal, image_size: 256,
init_lr: 1e-05, k_test: 256, max_epoch: 6, min_lr: 0, negative_all_rank: false, pretrained: https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base.pth,
queue_size: 512, test_path: /workspace/multimodal/data/multimodal/iid_test_small.json,
train_path: /workspace/multimodal/data/multimodal/train.json, val_path: /workspace/multimodal/data/multimodal/val_small.json,
vit: base, vit_ckpt_layer: 4, vit_grad_ckpt: true, weight_decay: 0.05}
